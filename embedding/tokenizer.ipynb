{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실무 테스트 - 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null 확인 Unnamed: 0                0\n",
      "brand_code                0\n",
      "id                        0\n",
      "sentiment                 0\n",
      "review_id                 0\n",
      "review_tag_type_id        0\n",
      "keywords                 64\n",
      "message                   0\n",
      "product_id                0\n",
      "product_name          15408\n",
      "created_at                0\n",
      "dtype: int64 \n",
      "\n",
      "Unnamed: 0             int64\n",
      "brand_code            object\n",
      "id                     int64\n",
      "sentiment              int64\n",
      "review_id              int64\n",
      "review_tag_type_id     int64\n",
      "keywords              object\n",
      "message               object\n",
      "product_id             int64\n",
      "product_name          object\n",
      "created_at            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"my_data/review_tags.csv\")\n",
    "\n",
    "print(\"null 확인\",df.isnull().sum(),\"\\n\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bnum'] = df['keywords'].apply(lambda x : x.split(\",\")[0])\n",
    "df['enum'] =  df['keywords'].apply(lambda x : x.split(\",\")[1])\n",
    "\n",
    "df['bnum'] = [re.sub('[^a-zA-Z0-9가-힣\\s]', '', df['bnum'][x]) for x in range(0,len(df)) ]\n",
    "df['enum'] = [re.sub('[^a-zA-Z0-9가-힣\\s]', '', df['enum'][x]) for x in range(0,len(df)) ]\n",
    "\n",
    "df['highlight'] = [df['message'][x][int(df['bnum'][x]):int(df['enum'][x])] for x in range(0,len(df)) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**하이라이트 테이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_message = df.drop_duplicates(['highlight'], keep='first').dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null 확인 Unnamed: 0            0\n",
      "brand_code            0\n",
      "id                    0\n",
      "sentiment             0\n",
      "review_id             0\n",
      "review_tag_type_id    0\n",
      "keywords              0\n",
      "message               0\n",
      "product_id            0\n",
      "product_name          0\n",
      "created_at            0\n",
      "bnum                  0\n",
      "enum                  0\n",
      "highlight             0\n",
      "dtype: int64 \n",
      "\n",
      "길이 585301\n"
     ]
    }
   ],
   "source": [
    "print(\"null 확인\",df_message.isnull().sum(),\"\\n\")\n",
    "print(\"길이\",len(df_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_list = df_message['highlight'].tolist()\n",
    "brand_list = df_message['brand_code'].tolist()\n",
    "id_list = df_message['review_id'].tolist()\n",
    "high_list = df_message['highlight'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(ms_list)==len(brand_list)==len(id_list)==len(df_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**리뷰 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKI_REMOVE_CHARS = re.compile(\"'+|(=+.{2,30}=+)|__TOC__|(ファイル:).+|:(en|de|it|fr|es|kr|zh|no|fi):|\\n\", re.UNICODE)\n",
    "WIKI_SPACE_CHARS = re.compile(\"(\\\\s|゙|゚|　)+\", re.UNICODE)\n",
    "EMAIL_PATTERN = re.compile(\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\", re.UNICODE)\n",
    "MULTIPLE_SPACES = re.compile(' +', re.UNICODE)\n",
    "# URL_PATTERN = re.compile(\"(ftp|http|https)?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", re.UNICODE)\n",
    "# WIKI_REMOVE_TOKEN_CHARS = re.compile(\"(\\\\*$|:$|^파일:.+|^;)\", re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_list = [re.sub(EMAIL_PATTERN, ' ', x) for x in ms_list]  # remove email pattern\n",
    "ms_list = [re.sub(WIKI_REMOVE_CHARS, ' ', x) for x in ms_list]  \n",
    "ms_list = [re.sub(WIKI_SPACE_CHARS, ' ', x) for x in ms_list]     \n",
    "ms_list = [re.sub(MULTIPLE_SPACES, ' ', x) for x in ms_list]    \n",
    "# ms_list = re.sub(URL_PATTERN, ' ', ms_list) # remove url pattern\n",
    "# tokens = ms_list.replace(\", )\", \"\").split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터&토큰나이저 입력 단위 길이\n",
    "length = 50000\n",
    "\n",
    "text = \"\\n\".join(ms_list[0:length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사이즈가 색별로 조금식 다른건지 물건마다 다른건지 좀 다르네'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**지도토크나이저 mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 생성\n",
    "path = \"my_data/mecab_list.txt\"\n",
    "\n",
    "with open(path, 'w') as f:\n",
    "    for i in range(0,1000):\n",
    "        item = \" \".join(tokenizer.morphs(text.split(\"\\n\")[i]))\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**리뷰 토큰 테이블 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "for i in range(0,100):\n",
    "    df_new = pd.DataFrame(tokenizer.pos(text.split(\"\\n\")[i]),columns = ['token','pos'])\n",
    "    df_new['brand_code'] = brand_list[i]\n",
    "    df_new['review_id'] = id_list[i]\n",
    "    df_new['highlight'] = high_list[i]\n",
    "    final_df = pd.concat([df_new,final_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['nchar'] = final_df['token'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_df = final_df[final_df['nchar']==1 & final_df['pos'].str.contains('^N') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(final_df, anti_df, how='outer', indicator=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.query(\"_merge=='left_only'\")\n",
    "final_df = final_df.drop(columns=['_merge','nchar'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**동사 명사 형용사만 남기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = \"^NN|^VA|^VV|^VX|^XR|MAG\"\n",
    "\n",
    "final_df = final_df[final_df['pos'].str.contains(pos) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_da(row):\n",
    "    if row['pos'].startswith('V'):  \n",
    "        return row['token'] + '다'\n",
    "    return row['token']\n",
    "\n",
    "\n",
    "final_df['new_token'] = final_df.apply(lambda row: add_da(row), axis=1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**리뷰 태그 아이디 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(final_df, df[['review_tag_type_id','highlight','review_id','brand_code']], how='left', on=['brand_code','review_id','highlight'])\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**top k 집계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['nchar'] = final_df['pos'].str.len()\n",
    "\n",
    "gdf = final_df[final_df['nchar']< 4 ].groupby('new_token')['new_token'].count().reset_index(name='counts')\n",
    "gdf.sort_values(by=['counts'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_token</th>\n",
       "      <th>counts</th>\n",
       "      <th>perc</th>\n",
       "      <th>running_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>좋다</td>\n",
       "      <td>42</td>\n",
       "      <td>0.069536</td>\n",
       "      <td>0.069536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>입다</td>\n",
       "      <td>33</td>\n",
       "      <td>0.054636</td>\n",
       "      <td>0.124172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>사이즈</td>\n",
       "      <td>22</td>\n",
       "      <td>0.036424</td>\n",
       "      <td>0.160596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>있다</td>\n",
       "      <td>15</td>\n",
       "      <td>0.024834</td>\n",
       "      <td>0.185430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>잘</td>\n",
       "      <td>13</td>\n",
       "      <td>0.021523</td>\n",
       "      <td>0.206954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  new_token  counts      perc  running_total\n",
       "0        좋다      42  0.069536       0.069536\n",
       "1        입다      33  0.054636       0.124172\n",
       "2       사이즈      22  0.036424       0.160596\n",
       "3        있다      15  0.024834       0.185430\n",
       "4         잘      13  0.021523       0.206954"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = gdf.reset_index(drop=True)\n",
    "\n",
    "gdf['perc'] = gdf['counts']/sum(gdf['counts'])\n",
    "gdf['running_total'] = gdf['perc'].cumsum()\n",
    "\n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_token</th>\n",
       "      <th>counts</th>\n",
       "      <th>perc</th>\n",
       "      <th>running_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>좋다</td>\n",
       "      <td>42</td>\n",
       "      <td>0.069536</td>\n",
       "      <td>0.069536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>입다</td>\n",
       "      <td>33</td>\n",
       "      <td>0.054636</td>\n",
       "      <td>0.124172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>사이즈</td>\n",
       "      <td>22</td>\n",
       "      <td>0.036424</td>\n",
       "      <td>0.160596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>있다</td>\n",
       "      <td>15</td>\n",
       "      <td>0.024834</td>\n",
       "      <td>0.185430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>잘</td>\n",
       "      <td>13</td>\n",
       "      <td>0.021523</td>\n",
       "      <td>0.206954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  new_token  counts      perc  running_total\n",
       "0        좋다      42  0.069536       0.069536\n",
       "1        입다      33  0.054636       0.124172\n",
       "2       사이즈      22  0.036424       0.160596\n",
       "3        있다      15  0.024834       0.185430\n",
       "4         잘      13  0.021523       0.206954"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(gdf[gdf['perc'] <= 0.9]) > 1000:\n",
    "    top_df = gdf.iloc[:1000,:]\n",
    "else:\n",
    "    top_df = gdf[gdf['perc'] <= 0.9]\n",
    "    \n",
    "top_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실무 테스트 - 임베딩 모델 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_fname = \"my_data/mecab_list.txt\"\n",
    "model_fname = \"my_data/word2vec\"\n",
    "\n",
    "# from gensim.models import Word2Vec\n",
    "\n",
    "# corpus = [sent.strip().split(\" \") for sent in open(corpus_fname, 'r').readlines()]\n",
    "# model = Word2Vec(corpus, size = 100, workers = 8, sg =0)\n",
    "# model.save(model_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.word_eval import WordEmbeddingEvaluator\n",
    "# model = WordEmbeddingEvaluator(model_fname, method = \"word2vec\", dim =100, tokenizer_name = \"mecab\")\n",
    "# model.most_similar(\"사이즈\",topn = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**top p 데이터 유사토큰 점검"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from gensim.models import Word2Vec\n",
    "from fasttext import load_model as load_ft_model\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from soynlp.hangle import compose, character_is_korean\n",
    "from preprocess import get_tokenizer, jamo_sentence\n",
    "\n",
    "sys.path.append('models')\n",
    "from visualize_utils import visualize_words, visualize_between_words\n",
    "import sys, re, argparse\n",
    "from khaiii import KhaiiiApi\n",
    "from konlpy.tag import Okt, Komoran, Mecab, Hannanum, Kkma\n",
    "\n",
    "\n",
    "\n",
    "def get_tokenizer(tokenizer_name):\n",
    "    if tokenizer_name == \"komoran\":\n",
    "        tokenizer = Komoran()\n",
    "    elif tokenizer_name == \"okt\":\n",
    "        tokenizer = Okt()\n",
    "    elif tokenizer_name == \"mecab\":\n",
    "        tokenizer = Mecab()\n",
    "    elif tokenizer_name == \"hannanum\":\n",
    "        tokenizer = Hannanum()\n",
    "    elif tokenizer_name == \"kkma\":\n",
    "        tokenizer = Kkma()\n",
    "    elif tokenizer_name == \"khaiii\":\n",
    "        tokenizer = KhaiiiApi()\n",
    "    else:\n",
    "        tokenizer = Mecab()\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "\n",
    "class WordEmbeddingEvaluator2:\n",
    "\n",
    "    def __init__(self, vecs_txt_fname, vecs_bin_fname=None, method=\"word2vec\", dim=100, tokenizer_name=\"mecab\"):\n",
    "        self.tokenizer = get_tokenizer(tokenizer_name)\n",
    "        self.tokenizer_name = tokenizer_name\n",
    "        self.dim = dim\n",
    "        self.method = method\n",
    "        self.dictionary, self.words, self.vecs = self.load_vectors(vecs_txt_fname, method)\n",
    "        if \"fasttext\" in method:\n",
    "            self.model = load_ft_model(vecs_bin_fname)\n",
    "        \n",
    "\n",
    "    def load_vectors(self, vecs_fname, method):\n",
    "        if method == \"word2vec\":\n",
    "            model = Word2Vec.load(vecs_fname)\n",
    "            words = model.wv.index2word\n",
    "            vecs = model.wv.vectors\n",
    "        else:\n",
    "            words, vecs = [], []\n",
    "            with open(vecs_fname, 'r', encoding='utf-8') as f:\n",
    "                if \"fasttext\" in method:\n",
    "                    next(f)  # skip head line\n",
    "                for line in f:\n",
    "                    if method == \"swivel\":\n",
    "                        splited_line = line.strip().split(\"\\t\")\n",
    "                    else:\n",
    "                        splited_line = line.strip().split(\" \")\n",
    "                    words.append(splited_line[0])\n",
    "                    vec = [float(el) for el in splited_line[1:]]\n",
    "                    vecs.append(vec)\n",
    "        unit_vecs = normalize(vecs, norm='l2', axis=1)\n",
    "        dictionary = {}\n",
    "        for word, vec in zip(words, unit_vecs):\n",
    "            dictionary[word] = vec\n",
    "        return dictionary, words, unit_vecs\n",
    "\n",
    "    def get_word_vector(self, word):\n",
    "        if self.method == \"fasttext-jamo\":\n",
    "            word = jamo_sentence(word)\n",
    "        if self._is_in_vocabulary(word):\n",
    "            vector = self.dictionary[word]\n",
    "        else:\n",
    "            if \"fasttext\" in self.method:\n",
    "                vector = self.model.get_word_vector(word)\n",
    "            else:\n",
    "                vector = np.zeros(self.dim)\n",
    "        return vector\n",
    "\n",
    "    # token vector들을 lookup한 뒤 평균을 취한다\n",
    "    def get_sentence_vector(self, sentence):\n",
    "        if self.tokenizer_name == \"khaiii\":\n",
    "            tokens = []\n",
    "            for word in self.tokenizer.analyze(sentence):\n",
    "                tokens.extend([str(m).split(\"/\")[0] for m in word.morphs])\n",
    "        else:\n",
    "            tokens = self.tokenizer.morphs(sentence)\n",
    "        token_vecs = []\n",
    "        for token in tokens:\n",
    "            token_vecs.append(self.get_word_vector(token))\n",
    "        return np.mean(token_vecs, axis=0)\n",
    "\n",
    "    def _is_in_vocabulary(self, word):\n",
    "        if self.method == \"fasttext-jamo\":\n",
    "            word = jamo_sentence(word)\n",
    "        return word in self.dictionary.keys()\n",
    "\n",
    "    def most_similar(self, query, topn=10):\n",
    "        query_vec = self.get_sentence_vector(query)\n",
    "        return self.most_similar_by_vector(query_vec, topn)\n",
    "\n",
    "    def most_similar_by_vector(self, query_vec, topn=10):\n",
    "        query_vec_norm = np.linalg.norm(query_vec)\n",
    "        if query_vec_norm != 0:\n",
    "            query_unit_vec = query_vec / query_vec_norm\n",
    "        else:\n",
    "            query_unit_vec = query_vec\n",
    "        scores = np.dot(self.vecs, query_unit_vec)\n",
    "        topn_candidates = sorted(zip(self.words, scores), key=lambda x: x[1], reverse=True)[1:topn+1]\n",
    "        total_list = []\n",
    "        for i in range(0,len(topn_candidates)):\n",
    "            total_list.append(topn_candidates[i][0])\n",
    "        return total_list\n",
    "\n",
    "    def jamo_to_word(self, jamo):\n",
    "        jamo_list, idx = [], 0\n",
    "        while idx < len(jamo):\n",
    "            if not character_is_korean(jamo[idx]):\n",
    "                jamo_list.append(jamo[idx])\n",
    "                idx += 1\n",
    "            else:\n",
    "                jamo_list.append(jamo[idx:idx + 3])\n",
    "                idx += 3\n",
    "        word = \"\"\n",
    "        for jamo_char in jamo_list:\n",
    "            if len(jamo_char) == 1:\n",
    "                word += jamo_char\n",
    "            elif jamo_char[2] == \"-\":\n",
    "                word += compose(jamo_char[0], jamo_char[1], \" \")\n",
    "            else:\n",
    "                word += compose(jamo_char[0], jamo_char[1], jamo_char[2])\n",
    "        return word\n",
    "\n",
    "    \"\"\"\n",
    "    Word similarity test\n",
    "    Inspired by:\n",
    "    https://github.com/dongjun-Lee/kor2vec/blob/master/test/similarity_test.py\n",
    "    \"\"\"\n",
    "    def word_sim_test(self, test_fname):\n",
    "        actual_sim_list, pred_sim_list = [], []\n",
    "        missed = 0\n",
    "        with open(test_fname, 'r') as pairs:\n",
    "            for pair in pairs:\n",
    "                w1, w2, actual_sim = pair.strip().split(\",\")\n",
    "                try:\n",
    "                    w1_vec = self.get_sentence_vector(w1)\n",
    "                    w2_vec = self.get_sentence_vector(w2)\n",
    "                    score = np.dot(w1_vec, w2_vec)\n",
    "                    actual_sim_list.append(float(actual_sim))\n",
    "                    pred_sim_list.append(score)\n",
    "                except KeyError:\n",
    "                    missed += 1\n",
    "        spearman, _ = st.spearmanr(actual_sim_list, pred_sim_list)\n",
    "        pearson, _ = st.pearsonr(actual_sim_list, pred_sim_list)\n",
    "        print(\"spearman corr:\", spearman, \", pearson corr:\", pearson, \", # of errors:\", missed)\n",
    "\n",
    "    \"\"\"\n",
    "    Word Analogy test\n",
    "    Inspired by:\n",
    "    https://github.com/dongjun-Lee/kor2vec/blob/master/test/analogy_test.py\n",
    "    \"\"\"\n",
    "    def word_analogy_test(self, test_fname, topn=30, verbose=False):\n",
    "        correct, total, missed = 0, 0, 0\n",
    "        with open(test_fname, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"#\") or len(line) <= 1:\n",
    "                    continue\n",
    "                words = line.strip().split(\" \")\n",
    "                query_vecs = self.get_analogy_vector(words[:-1])\n",
    "                try:\n",
    "                    word_with_scores = self.most_similar_by_vector(query_vecs, topn)\n",
    "                    if verbose:\n",
    "                        print(words[0] + \" - \" + words[1] + \" + \" + words[2])\n",
    "                        print(\"correct answer:\", words[3])\n",
    "                        print(\"predicted answers:\", word_with_scores)\n",
    "                        print(\"\")\n",
    "                    similar_words = [el[0] for el in word_with_scores]\n",
    "                    if words[-1] in similar_words:\n",
    "                        correct += 1\n",
    "                except:\n",
    "                    missed += 1\n",
    "                total += 1\n",
    "        print(\"# of correct answer:\", correct, \", # of data:\", total, \", # of errors:\", missed)\n",
    "\n",
    "    def get_analogy_vector(self, words):\n",
    "        if len(words) == 3:\n",
    "            token_1 = self.get_sentence_vector(words[0])\n",
    "            token_2 = self.get_sentence_vector(words[1])\n",
    "            token_3 = self.get_sentence_vector(words[2])\n",
    "            result = token_2 + token_3 - token_1\n",
    "        else:\n",
    "            result = np.zeros(self.dim)\n",
    "        return result\n",
    "\n",
    "    \"\"\"\n",
    "    Visualize word representions with T-SNE, Bokeh\n",
    "    Inspired by:\n",
    "    https://www.kaggle.com/yohanb/t-sne-bokeh\n",
    "    https://bokeh.pydata.org\n",
    "    \"\"\"\n",
    "    def visualize_words(self, words_fname, palette=\"Viridis256\"):\n",
    "        words = set()\n",
    "        for line in open(words_fname, 'r', encoding='utf-8'):\n",
    "            if not line.startswith(\"#\"):\n",
    "                for word in line.strip().split(\" \"):\n",
    "                    if len(word) > 0:\n",
    "                        words.add(word)\n",
    "        vecs = np.array([self.get_sentence_vector(word) for word in words])\n",
    "        visualize_words(words, vecs, palette)\n",
    "\n",
    "    def visualize_between_words(self, words_fname, palette=\"Viridis256\"):\n",
    "        words = set()\n",
    "        for line in open(words_fname, 'r'):\n",
    "            if not line.startswith(\"#\"):\n",
    "                for word in line.strip().split(\" \"):\n",
    "                    if len(word) > 0:\n",
    "                        words.add(word)\n",
    "        vecs = [self.get_sentence_vector(word) for word in words]\n",
    "        visualize_between_words(words, vecs, palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "model = WordEmbeddingEvaluator2(model_fname, method = \"word2vec\", dim =100, tokenizer_name = \"mecab\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df['similar_list'] = [model.most_similar(top_df['new_token'][i],topn = 15) for i in range(0,len(top_df))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_token</th>\n",
       "      <th>counts</th>\n",
       "      <th>perc</th>\n",
       "      <th>running_total</th>\n",
       "      <th>similar_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>좋다</td>\n",
       "      <td>42</td>\n",
       "      <td>0.069536</td>\n",
       "      <td>0.069536</td>\n",
       "      <td>[다, 괜찮, 정말, 별, 마음, 맘, 너무너무, 추가, 참, 넘, 도, 너무나, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>입다</td>\n",
       "      <td>33</td>\n",
       "      <td>0.054636</td>\n",
       "      <td>0.124172</td>\n",
       "      <td>[다, 입혀, 입히, 다네, 막상, 코디, 매치, 갖, 입힐, 밖, 받쳐입, 착용,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>사이즈</td>\n",
       "      <td>22</td>\n",
       "      <td>0.036424</td>\n",
       "      <td>0.160596</td>\n",
       "      <td>[즈, 95, 105, 치수, 싸이, 85, 크기, 100, 사이, 평소, 선택, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>있다</td>\n",
       "      <td>15</td>\n",
       "      <td>0.024834</td>\n",
       "      <td>0.185430</td>\n",
       "      <td>[다, 잇, 없, 로운, 어쩔, 정치, 느낄, 처리, 없이, 롭, 벤딩, 모르, 야...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>잘</td>\n",
       "      <td>13</td>\n",
       "      <td>0.021523</td>\n",
       "      <td>0.206954</td>\n",
       "      <td>[딱, 자주, 요긴, 편하, 으려고, 트랜드, 얼추, 수, 가볍, 정말, 이쁘, 올...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>맞다</td>\n",
       "      <td>13</td>\n",
       "      <td>0.021523</td>\n",
       "      <td>0.228477</td>\n",
       "      <td>[맞, 맞음, 어울린다고, 이즈라, 85, 90, 정사, 95, 빠졌, 어요, 받,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>같다</td>\n",
       "      <td>13</td>\n",
       "      <td>0.021523</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>[같, 애요, 습니다, 네요, 지요, 말, 올라옵니다, 곤, 어요, 습니, 듯, 였...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>좀</td>\n",
       "      <td>10</td>\n",
       "      <td>0.016556</td>\n",
       "      <td>0.266556</td>\n",
       "      <td>[조금, 살짝, 약간, 다소, 쫌, 많이, 통, 다리, 어깨, 소매, 오히려, 나오...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>재질</td>\n",
       "      <td>9</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>0.281457</td>\n",
       "      <td>[원단, 촉감, 소재, 옷감, 감촉, 천, 질감, 착용감, 색감, 품질, 질, 안감...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>너무</td>\n",
       "      <td>9</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>0.296358</td>\n",
       "      <td>[넘, 너무너무, 아주, 엄청, 정말, 진짜, 도, 너무나, 흔하, 완전, 이뻐요,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>딱</td>\n",
       "      <td>9</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>0.311258</td>\n",
       "      <td>[잘, 계절, 작당, 지금, 알맞, 요즘, 안성맞춤, 81, 찰떡, 트랜드, 적당,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>소재</td>\n",
       "      <td>8</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.324503</td>\n",
       "      <td>[재질, 원단, 촉감, 감촉, 캐시미어, 피부, 천, 옷감, 기모, 안감, 착용감,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>얇다</td>\n",
       "      <td>8</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.337748</td>\n",
       "      <td>[다, 괜찮, 까칠, 부드럽, 겉, 나일론, 보들보들, 엷, 두껍, 도톰, 깜, 부...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>편하다</td>\n",
       "      <td>8</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.350993</td>\n",
       "      <td>[다, 편해서, 편해, 예쁘, 다니, 어, 이쁘, 가볍, 다녀, 어요, 다네, 편안...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>않다</td>\n",
       "      <td>8</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.364238</td>\n",
       "      <td>[않, 못하, 마세요, 고급, 더라구, 앤드, 환해, 베이, 입혀, 못했, 세련, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>여름</td>\n",
       "      <td>8</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.377483</td>\n",
       "      <td>[겨울, 환절기, 초가을, 가을, 초겨울, 날씨, 속, 늦가을, 지금, 겉, 봄, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>시원</td>\n",
       "      <td>7</td>\n",
       "      <td>0.011589</td>\n",
       "      <td>0.389073</td>\n",
       "      <td>[따듯, 톡톡, 탄탄, 부들부들, 쫀쫀, 따뜻, 포근, 두툼, 도톰, 편안, 짱짱,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>허리</td>\n",
       "      <td>7</td>\n",
       "      <td>0.011589</td>\n",
       "      <td>0.400662</td>\n",
       "      <td>[허벅지, 엉덩이, 어깨, 소매, 밴드, 밑단, 다리, 통, 시보리, 발목, 종아리...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>색상</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>0.410596</td>\n",
       "      <td>[색깔, 색, 컬러, 색감, 색도, 디자인, 블랙, 칼라, 회색, 카키색, 흰색, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>크다</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>0.420530</td>\n",
       "      <td>[다, 커서, 작, 큰, 넉넉, 90, 널널, 낙낙, 헐렁, 타이트, 더니, 올려서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>구매</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>0.430464</td>\n",
       "      <td>[구입, 주문, 득템, 선택, 사, 장만, 신청, 고민, 샀, 긴가민가, 선물, 쟁...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>상품</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>0.440397</td>\n",
       "      <td>[제품, 물건, 품질, 금액, 기분, 가격, 옷, 퀄리티, 할인, 항상, 몰, 곳,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>조금</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>0.450331</td>\n",
       "      <td>[좀, 살짝, 약간, 다소, 쫌, 통, 많이, 어깨, 소매, 다리, 팔, 긴, 가슴...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>드다</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>0.458609</td>\n",
       "      <td>[듭니다, 듭니, 다, 드, 듬, 쏙, 든다, 듦, 대요, 데요, 들, 색도, 칼라...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>베이지</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>0.466887</td>\n",
       "      <td>[아이보리, 핑크, 네이비, 그레이, 민트, 카키, 연한, 카키색, 그린, 그레, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>색감</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>0.475166</td>\n",
       "      <td>[색상, 질감, 디자인, 색깔, 옷감, 컬러, 촉감, 감촉, 착용감, 색, 패턴, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>괜찮다</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>0.483444</td>\n",
       "      <td>[괜찮, 좋, 이랑, 다른, 똑같, ,, 모두, 괜찬, 받, 별, 전부, 둘, 나름...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>마음</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>0.491722</td>\n",
       "      <td>[맘, 애, 가족, 뷰, 예쁘, 예뻐, 이뻐, 이쁘, 예뻐서, 심플, 다른, 쿨, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>부분</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.498344</td>\n",
       "      <td>[밑단, 쪽, 발목, 목, 끈, 통, 시보리, 고무줄, 넓, 엉덩이, 라인, 허벅지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>고급</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.504967</td>\n",
       "      <td>[자연, 멋, 환해, 연하, 세련, 패턴, 화사, 얼굴, 보들, 튼튼, 부드러운, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>시보리</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.951987</td>\n",
       "      <td>[단추, 밑단, 주머니, 소매, 카라, 밑위, 밴드, 발목, 허벅지, 종아리, 고무...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>시작</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.953642</td>\n",
       "      <td>[쌀, 둡, 찝찝, 오늘, 챙겨, 쉬워, 운전, 헬스, 적합, 외출, 소장, 간단,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>실물</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.955298</td>\n",
       "      <td>[실제, 그린, 진한, 민트, 그레, 연한, 베이지, 카키, 핑크, 카키색, 하늘색...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>싸다</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.956954</td>\n",
       "      <td>[다, 어요, 저렴, 또, 세일, 히, 할인, 착한, 재, 어용, 다시, 너무나, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>쌀쌀</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.958609</td>\n",
       "      <td>[쌀쌀, 찬바람, 저녁, 시작, 서늘, 선선, 아침, 외출, 곧, 추워진, 산책, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>살다</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.960265</td>\n",
       "      <td>[살, 어쩔, 는지, 시킬, 사고, 들어갈, 다는, 살까, 그걸로, 이게, 나올, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>사다</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.961921</td>\n",
       "      <td>[사, 사고, 구매, 입혀, 사놓, 직접, 주문, 쟁이, 별, 살까, 깔, 선물, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>모두</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.963576</td>\n",
       "      <td>[및, 전부, 또한, 며, 모든, 이나, 등, ,, 등등, 과, 이랑, 비해서, :...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>변경</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.965232</td>\n",
       "      <td>[우려, 바보, 자동, 취소, 어찌, 한참, 이야기, 물빨래, 판단, 매진, 안내,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>몸매</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>[나이, 글자, 목둘레, 녀, 뱃살, 하체비만, 낌, 가공, 커버, 깃털, 찐, 봉...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>몸통</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.968543</td>\n",
       "      <td>[총장, 바지통, 가슴, 어깨선, 종아리, 둘레, 다리통, 가슴둘레, 넓이, 소매길...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>무게</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.970199</td>\n",
       "      <td>[두께, 사합, 두깨, 터치, 무거운, 거부, 으며, 길이, 자체, 크기, 옷감, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>물건</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.971854</td>\n",
       "      <td>[상품, 적립금, 군데, 시간, 금액, 할께, 생일, 와서, 기다렸, 포장, 쇼핑,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>미리</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.973510</td>\n",
       "      <td>[준비, 시즌, 이번, 오늘, 위해, 장, 할려고, 달, 써서, 려구요, 놔서, 려...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>바로</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.975166</td>\n",
       "      <td>[몇, 러, 장, 첫, 오늘, 자마자, 계속, 다시, 후, 반품, 또, 기회, 마침...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>받다</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.976821</td>\n",
       "      <td>[받, 입혀, 직접, 실제로, 막상, 온, 결정, 자세히, 자마자, 알, 와서, 도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>발목</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.978477</td>\n",
       "      <td>[밑단, 엉덩이, 덮, 부분, 고무, 종아리, 다리, 시보리, 고무줄, 허벅지, 밑...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>밴드</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.980132</td>\n",
       "      <td>[고무줄, 고무, 밴, 허벅지, 시보리, 엉덩이, 조임, 딩, 허리, 발목, 조이,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>보다</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.981788</td>\n",
       "      <td>[다, 막상, 실제로, 둘, 본, 매장, 인터넷, 칭찬, 직접, 결국, 다며, 지인...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>사니</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.983444</td>\n",
       "      <td>[이이, 131, 낙낙히, 저스트, 43, 46, 엉, 18, 시켜서, 161, =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>보이다</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.985099</td>\n",
       "      <td>[다, 보여, 보여요, 막상, 보여서, 날씬, 실제로, 얘, 화사, 져, 뚱뚱, 흐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>부드럽다</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.986755</td>\n",
       "      <td>[다, 부드러워, 보들보들, 부들부들, 착용감, 보드랍, 촉감, 부드러워서, 부들,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>분리</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.988411</td>\n",
       "      <td>[빨라, 빠, 묶음, 빠릅니다, 무료, 지연, 느려서, 빨라요, 빠른, 느려, 물량...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>브다</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.990066</td>\n",
       "      <td>[브, 렌, 뷰, 식구, 줌, 캐시, 매끄러운, 우리, 더라고요, 멀리서, 꼭지, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>비슷</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.991722</td>\n",
       "      <td>[동일, 비교, 유사, 탁월, 어중간, 베이직, 차분, 은은, 깨끗, 산뜻, 다운,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>비치다</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>[다, 비치, 거칠, 다른데, 약해, 따갑, 따끔, 물, 두꺼웠, 노란, 뭔가, 따...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>빠르다</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.995033</td>\n",
       "      <td>[다, 빠르, 빨랐, 빨리, 빠, 빨라, 빨라요, 빠릅니다, 빠른, 무료, 분리, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>빳빳</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.996689</td>\n",
       "      <td>[뻣뻣, 까칠, 까슬까슬, 까끌까끌, 펑퍼짐, 답답, 까끌, 탄탄, 심심, 칙칙, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>뽑다</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.998344</td>\n",
       "      <td>[다, 자세히, 더라고, 일어났, 멀리서, 뭘, 입혀, 매해, 직접, 습니당, 다며...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>훨씬</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[무엇, 사진, 예상, 화면, 생가, 실제, 민트, 보세, 생각, 핑크, 실제로, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    new_token  counts      perc  running_total  \\\n",
       "0          좋다      42  0.069536       0.069536   \n",
       "1          입다      33  0.054636       0.124172   \n",
       "2         사이즈      22  0.036424       0.160596   \n",
       "3          있다      15  0.024834       0.185430   \n",
       "4           잘      13  0.021523       0.206954   \n",
       "5          맞다      13  0.021523       0.228477   \n",
       "6          같다      13  0.021523       0.250000   \n",
       "7           좀      10  0.016556       0.266556   \n",
       "8          재질       9  0.014901       0.281457   \n",
       "9          너무       9  0.014901       0.296358   \n",
       "10          딱       9  0.014901       0.311258   \n",
       "11         소재       8  0.013245       0.324503   \n",
       "12         얇다       8  0.013245       0.337748   \n",
       "13        편하다       8  0.013245       0.350993   \n",
       "14         않다       8  0.013245       0.364238   \n",
       "15         여름       8  0.013245       0.377483   \n",
       "16         시원       7  0.011589       0.389073   \n",
       "17         허리       7  0.011589       0.400662   \n",
       "18         색상       6  0.009934       0.410596   \n",
       "19         크다       6  0.009934       0.420530   \n",
       "20         구매       6  0.009934       0.430464   \n",
       "21         상품       6  0.009934       0.440397   \n",
       "22         조금       6  0.009934       0.450331   \n",
       "23         드다       5  0.008278       0.458609   \n",
       "24        베이지       5  0.008278       0.466887   \n",
       "25         색감       5  0.008278       0.475166   \n",
       "26        괜찮다       5  0.008278       0.483444   \n",
       "27         마음       5  0.008278       0.491722   \n",
       "28         부분       4  0.006623       0.498344   \n",
       "29         고급       4  0.006623       0.504967   \n",
       "..        ...     ...       ...            ...   \n",
       "212       시보리       1  0.001656       0.951987   \n",
       "213        시작       1  0.001656       0.953642   \n",
       "214        실물       1  0.001656       0.955298   \n",
       "215        싸다       1  0.001656       0.956954   \n",
       "216        쌀쌀       1  0.001656       0.958609   \n",
       "217        살다       1  0.001656       0.960265   \n",
       "218        사다       1  0.001656       0.961921   \n",
       "219        모두       1  0.001656       0.963576   \n",
       "220        변경       1  0.001656       0.965232   \n",
       "221        몸매       1  0.001656       0.966887   \n",
       "222        몸통       1  0.001656       0.968543   \n",
       "223        무게       1  0.001656       0.970199   \n",
       "224        물건       1  0.001656       0.971854   \n",
       "225        미리       1  0.001656       0.973510   \n",
       "226        바로       1  0.001656       0.975166   \n",
       "227        받다       1  0.001656       0.976821   \n",
       "228        발목       1  0.001656       0.978477   \n",
       "229        밴드       1  0.001656       0.980132   \n",
       "230        보다       1  0.001656       0.981788   \n",
       "231        사니       1  0.001656       0.983444   \n",
       "232       보이다       1  0.001656       0.985099   \n",
       "233      부드럽다       1  0.001656       0.986755   \n",
       "234        분리       1  0.001656       0.988411   \n",
       "235        브다       1  0.001656       0.990066   \n",
       "236        비슷       1  0.001656       0.991722   \n",
       "237       비치다       1  0.001656       0.993377   \n",
       "238       빠르다       1  0.001656       0.995033   \n",
       "239        빳빳       1  0.001656       0.996689   \n",
       "240        뽑다       1  0.001656       0.998344   \n",
       "241        훨씬       1  0.001656       1.000000   \n",
       "\n",
       "                                          similar_list  \n",
       "0    [다, 괜찮, 정말, 별, 마음, 맘, 너무너무, 추가, 참, 넘, 도, 너무나, ...  \n",
       "1    [다, 입혀, 입히, 다네, 막상, 코디, 매치, 갖, 입힐, 밖, 받쳐입, 착용,...  \n",
       "2    [즈, 95, 105, 치수, 싸이, 85, 크기, 100, 사이, 평소, 선택, ...  \n",
       "3    [다, 잇, 없, 로운, 어쩔, 정치, 느낄, 처리, 없이, 롭, 벤딩, 모르, 야...  \n",
       "4    [딱, 자주, 요긴, 편하, 으려고, 트랜드, 얼추, 수, 가볍, 정말, 이쁘, 올...  \n",
       "5    [맞, 맞음, 어울린다고, 이즈라, 85, 90, 정사, 95, 빠졌, 어요, 받,...  \n",
       "6    [같, 애요, 습니다, 네요, 지요, 말, 올라옵니다, 곤, 어요, 습니, 듯, 였...  \n",
       "7    [조금, 살짝, 약간, 다소, 쫌, 많이, 통, 다리, 어깨, 소매, 오히려, 나오...  \n",
       "8    [원단, 촉감, 소재, 옷감, 감촉, 천, 질감, 착용감, 색감, 품질, 질, 안감...  \n",
       "9    [넘, 너무너무, 아주, 엄청, 정말, 진짜, 도, 너무나, 흔하, 완전, 이뻐요,...  \n",
       "10   [잘, 계절, 작당, 지금, 알맞, 요즘, 안성맞춤, 81, 찰떡, 트랜드, 적당,...  \n",
       "11   [재질, 원단, 촉감, 감촉, 캐시미어, 피부, 천, 옷감, 기모, 안감, 착용감,...  \n",
       "12   [다, 괜찮, 까칠, 부드럽, 겉, 나일론, 보들보들, 엷, 두껍, 도톰, 깜, 부...  \n",
       "13   [다, 편해서, 편해, 예쁘, 다니, 어, 이쁘, 가볍, 다녀, 어요, 다네, 편안...  \n",
       "14   [않, 못하, 마세요, 고급, 더라구, 앤드, 환해, 베이, 입혀, 못했, 세련, ...  \n",
       "15   [겨울, 환절기, 초가을, 가을, 초겨울, 날씨, 속, 늦가을, 지금, 겉, 봄, ...  \n",
       "16   [따듯, 톡톡, 탄탄, 부들부들, 쫀쫀, 따뜻, 포근, 두툼, 도톰, 편안, 짱짱,...  \n",
       "17   [허벅지, 엉덩이, 어깨, 소매, 밴드, 밑단, 다리, 통, 시보리, 발목, 종아리...  \n",
       "18   [색깔, 색, 컬러, 색감, 색도, 디자인, 블랙, 칼라, 회색, 카키색, 흰색, ...  \n",
       "19   [다, 커서, 작, 큰, 넉넉, 90, 널널, 낙낙, 헐렁, 타이트, 더니, 올려서...  \n",
       "20   [구입, 주문, 득템, 선택, 사, 장만, 신청, 고민, 샀, 긴가민가, 선물, 쟁...  \n",
       "21   [제품, 물건, 품질, 금액, 기분, 가격, 옷, 퀄리티, 할인, 항상, 몰, 곳,...  \n",
       "22   [좀, 살짝, 약간, 다소, 쫌, 통, 많이, 어깨, 소매, 다리, 팔, 긴, 가슴...  \n",
       "23   [듭니다, 듭니, 다, 드, 듬, 쏙, 든다, 듦, 대요, 데요, 들, 색도, 칼라...  \n",
       "24   [아이보리, 핑크, 네이비, 그레이, 민트, 카키, 연한, 카키색, 그린, 그레, ...  \n",
       "25   [색상, 질감, 디자인, 색깔, 옷감, 컬러, 촉감, 감촉, 착용감, 색, 패턴, ...  \n",
       "26   [괜찮, 좋, 이랑, 다른, 똑같, ,, 모두, 괜찬, 받, 별, 전부, 둘, 나름...  \n",
       "27   [맘, 애, 가족, 뷰, 예쁘, 예뻐, 이뻐, 이쁘, 예뻐서, 심플, 다른, 쿨, ...  \n",
       "28   [밑단, 쪽, 발목, 목, 끈, 통, 시보리, 고무줄, 넓, 엉덩이, 라인, 허벅지...  \n",
       "29   [자연, 멋, 환해, 연하, 세련, 패턴, 화사, 얼굴, 보들, 튼튼, 부드러운, ...  \n",
       "..                                                 ...  \n",
       "212  [단추, 밑단, 주머니, 소매, 카라, 밑위, 밴드, 발목, 허벅지, 종아리, 고무...  \n",
       "213  [쌀, 둡, 찝찝, 오늘, 챙겨, 쉬워, 운전, 헬스, 적합, 외출, 소장, 간단,...  \n",
       "214  [실제, 그린, 진한, 민트, 그레, 연한, 베이지, 카키, 핑크, 카키색, 하늘색...  \n",
       "215  [다, 어요, 저렴, 또, 세일, 히, 할인, 착한, 재, 어용, 다시, 너무나, ...  \n",
       "216  [쌀쌀, 찬바람, 저녁, 시작, 서늘, 선선, 아침, 외출, 곧, 추워진, 산책, ...  \n",
       "217  [살, 어쩔, 는지, 시킬, 사고, 들어갈, 다는, 살까, 그걸로, 이게, 나올, ...  \n",
       "218  [사, 사고, 구매, 입혀, 사놓, 직접, 주문, 쟁이, 별, 살까, 깔, 선물, ...  \n",
       "219  [및, 전부, 또한, 며, 모든, 이나, 등, ,, 등등, 과, 이랑, 비해서, :...  \n",
       "220  [우려, 바보, 자동, 취소, 어찌, 한참, 이야기, 물빨래, 판단, 매진, 안내,...  \n",
       "221  [나이, 글자, 목둘레, 녀, 뱃살, 하체비만, 낌, 가공, 커버, 깃털, 찐, 봉...  \n",
       "222  [총장, 바지통, 가슴, 어깨선, 종아리, 둘레, 다리통, 가슴둘레, 넓이, 소매길...  \n",
       "223  [두께, 사합, 두깨, 터치, 무거운, 거부, 으며, 길이, 자체, 크기, 옷감, ...  \n",
       "224  [상품, 적립금, 군데, 시간, 금액, 할께, 생일, 와서, 기다렸, 포장, 쇼핑,...  \n",
       "225  [준비, 시즌, 이번, 오늘, 위해, 장, 할려고, 달, 써서, 려구요, 놔서, 려...  \n",
       "226  [몇, 러, 장, 첫, 오늘, 자마자, 계속, 다시, 후, 반품, 또, 기회, 마침...  \n",
       "227  [받, 입혀, 직접, 실제로, 막상, 온, 결정, 자세히, 자마자, 알, 와서, 도...  \n",
       "228  [밑단, 엉덩이, 덮, 부분, 고무, 종아리, 다리, 시보리, 고무줄, 허벅지, 밑...  \n",
       "229  [고무줄, 고무, 밴, 허벅지, 시보리, 엉덩이, 조임, 딩, 허리, 발목, 조이,...  \n",
       "230  [다, 막상, 실제로, 둘, 본, 매장, 인터넷, 칭찬, 직접, 결국, 다며, 지인...  \n",
       "231  [이이, 131, 낙낙히, 저스트, 43, 46, 엉, 18, 시켜서, 161, =...  \n",
       "232  [다, 보여, 보여요, 막상, 보여서, 날씬, 실제로, 얘, 화사, 져, 뚱뚱, 흐...  \n",
       "233  [다, 부드러워, 보들보들, 부들부들, 착용감, 보드랍, 촉감, 부드러워서, 부들,...  \n",
       "234  [빨라, 빠, 묶음, 빠릅니다, 무료, 지연, 느려서, 빨라요, 빠른, 느려, 물량...  \n",
       "235  [브, 렌, 뷰, 식구, 줌, 캐시, 매끄러운, 우리, 더라고요, 멀리서, 꼭지, ...  \n",
       "236  [동일, 비교, 유사, 탁월, 어중간, 베이직, 차분, 은은, 깨끗, 산뜻, 다운,...  \n",
       "237  [다, 비치, 거칠, 다른데, 약해, 따갑, 따끔, 물, 두꺼웠, 노란, 뭔가, 따...  \n",
       "238  [다, 빠르, 빨랐, 빨리, 빠, 빨라, 빨라요, 빠릅니다, 빠른, 무료, 분리, ...  \n",
       "239  [뻣뻣, 까칠, 까슬까슬, 까끌까끌, 펑퍼짐, 답답, 까끌, 탄탄, 심심, 칙칙, ...  \n",
       "240  [다, 자세히, 더라고, 일어났, 멀리서, 뭘, 입혀, 매해, 직접, 습니당, 다며...  \n",
       "241  [무엇, 사진, 예상, 화면, 생가, 실제, 민트, 보세, 생각, 핑크, 실제로, ...  \n",
       "\n",
       "[242 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'explode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-6f70b13dcb3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'similar_list'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'explode'"
     ]
    }
   ],
   "source": [
    "top_df.explode('similar_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
